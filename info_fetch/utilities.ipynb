{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary package for the following function implments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from itertools import combinations\n",
    "import requests\n",
    "import time\n",
    "import ujson\n",
    "from itertools import combinations\n",
    "from itertools import permutations\n",
    "from collections import defaultdict\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following funtion take input of author's name and check author's formal name by the looking up in the MathScinet web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author_name(name):\n",
    "    url = 'https://mathscinet.ams.org/mathscinet/search/authors.html?authorName={}&Submit=Search'.format(name)\n",
    "    data = requests.get(url).content\n",
    "    content = BeautifulSoup(data, 'html.parser')\n",
    "    #identify = content.find('title').getText().split(' ')[-1].replace('\\n','')\n",
    "    result_name = content.find('span', {\"class\": \"authorName important\"})\n",
    "    if result_name:\n",
    "        return result_name.getText()\n",
    "    else:\n",
    "        print(\"Multiple name possible, please re-check your input\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following funtion take input of author's name and check author's id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author_id(name):\n",
    "    url = 'https://mathscinet.ams.org/mathscinet/search/authors.html?authorName={}&Submit=Search'.format(name)\n",
    "    data = requests.get(url).content\n",
    "    content = BeautifulSoup(data, 'html.parser')\n",
    "    identify = content.find('title').getText().split(' ')[-1].replace('\\n','')\n",
    "    return identify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each element in the list is a dict(), with paper title as key, list of author's name of current paper is the value\n",
    "\n",
    "The helper functions are implmented below the function \"fetch_list\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_list():\n",
    "    with open('faculties.txt', 'r') as file:\n",
    "        data = file.read()\n",
    "        names = data.split('\\n')\n",
    "\n",
    "    result = dict()\n",
    "    idx = 1\n",
    "    for i in names:\n",
    "        print(\"{}/{}Checking:{}\\n\".format(idx, len(names), i))\n",
    "        time.sleep(2)\n",
    "        url = search(i)\n",
    "        papers = fetch(url)\n",
    "        result[i] = papers\n",
    "        idx += 1\n",
    "\n",
    "    with open('data/publication_source.json', 'w') as file:\n",
    "        ujson.dump(result, file)\n",
    "    return result\n",
    "\n",
    "#This function find the url for searching result of input name\n",
    "def search(name):\n",
    "    first = 'https://mathscinet.ams.org/mathscinet/search/publications.html?pg4=AUCN&s4='\n",
    "    second = '&co4=AND&pg5=TI&s5=&co5=AND&pg6=PC&s6=&co6=AND&pg7=SE&s7=&co7=ANDdr=pubyear&yrop=gt&arg3=2010&yearRangeFirst=&yearRangeSecond=&pg8=ET&s8=All&review_format=pdf&Submit=Search'\n",
    "    return first + name + second\n",
    "\n",
    "\n",
    "#This function find the url of \"next\" button\n",
    "def findnext(start):\n",
    "    # start = 'https://mathscinet.ams.org//mathscinet/search/publications.html?arg3=&co4=AND&co5=AND&co6=AND&co7=AND&dr=all&pg4=AUCN&pg5=TI&pg6=PC&pg7=SE&pg8=ET&review_format=pdf&s4=Kleinberg%2C%20Jon&s5=&s6=&s7=&s8=All&sort=Newest&vfpref=pdf&yearRangeFirst=&yearRangeSecond=&yrop=eq&r=81'\n",
    "    time.sleep(0.5)\n",
    "    data = requests.get(start).content\n",
    "    content = BeautifulSoup(data, 'html.parser')\n",
    "    # Matches = content.find('div', {\"class\": \"matches\"}).get_text().replace('\\n', '')\n",
    "    # match_num = re.sub(r'\\D', \"\", Matches)\n",
    "\n",
    "    pages = content.find('div', {\"class\": \"navbar\"})\n",
    "\n",
    "    if not pages or len(pages) == 1:  # No next page button\n",
    "        # print(\"No next page! gg bro!\")\n",
    "        return False, None\n",
    "    else:\n",
    "        currnum = pages.find('span', {\"class\": \"CurrentPage\"}).get_text()\n",
    "        nextnum = pages.findAll('span', {\"class\": \"PageLink\"})[-1].get_text()\n",
    "\n",
    "        # print('curr page is: {}\\n curr url is:\\n{}\\n\\n'.format(currnum, start))\n",
    "\n",
    "        if nextnum < currnum:\n",
    "            # print(\"End of pages bro, time to stop\")\n",
    "            return False, None\n",
    "        else:\n",
    "            next = pages.findAll('span', {\"class\": \"PageLink\"})[-1]\n",
    "            link = 'https://mathscinet.ams.org/' + next.find('a', href=True)['href']\n",
    "            # print(link)\n",
    "            return True, link\n",
    "\n",
    "\n",
    "#This function extracts the info from the input url page\n",
    "def fetch(url):\n",
    "    data = requests.get(url).content\n",
    "\n",
    "    content = BeautifulSoup(data, 'html.parser')\n",
    "    #Key: title Value: list of author name\n",
    "    papers = dict() #dict for store the paper info.\n",
    "\n",
    "    heads = content.findAll('div', {\"class\": \"headline\"})\n",
    "    for head in heads:\n",
    "        # fetch the title in this paper\n",
    "        title = head.find('span', {\"class\": \"title\"}).getText()\n",
    "        ele = head.find('a', {\"class\": \"item_status\"}).getText()\n",
    "        authors = head.getText().replace('\\n', '').split(ele)[1:][0]\n",
    "\n",
    "        try:\n",
    "            authors = authors.split(title)[:-1][0]\n",
    "        except IndexError:\n",
    "            # print('Wrong: title:{}\\nauthor_list:{}\\nurl:{}\\n'.format(title,authors, url))\n",
    "            authors = authors.split(title.replace('\\n', ''))[:-1][0]\n",
    "            print(authors)\n",
    "\n",
    "        names = []\n",
    "        for author in authors.split(';'):\n",
    "            name = author.strip()\n",
    "            if name:\n",
    "                names.append(name)\n",
    "        papers[title] = names\n",
    "    # continue for future work\n",
    "    next, next_url = findnext(url)\n",
    "    if next:\n",
    "        next_paper = fetch(next_url)\n",
    "        total = {**papers, **next_paper}\n",
    "        return total\n",
    "    else:\n",
    "        return papers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function process the publication_source data and output the matrix of joint publication data between any pair of two authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_joint():\n",
    "    with open('data/publication_source.json') as file:\n",
    "        result = ujson.load(file)\n",
    "\n",
    "    pairs = combinations(result, 2)\n",
    "    joint = dict()\n",
    "    for i in pairs:\n",
    "        one, two = i\n",
    "        num = len(set(result[one]) & set(result[two]))\n",
    "\n",
    "        # num = 0\n",
    "        # for paper in result[one]:\n",
    "        #     if two in result[one][paper]:\n",
    "        #         num += 1\n",
    "        joint[i] = num\n",
    "\n",
    "    print(joint)\n",
    "    with open('joint.json', 'w') as file:\n",
    "        ujson.dump(joint, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function reads author name in certain files and fetch publication informations for the authors.\n",
    "Structure: list of authors name []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function collect the paper citation. If paper title repeat, it keeps the last appearance result data structure: dict. Key: title of paper, Value: list of citation paper title \n",
    "Two helper functions are implemented right below \"fetch_citation\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_citation(url):\n",
    "    data = requests.get(url).content\n",
    "    content = BeautifulSoup(data, 'html.parser')\n",
    "    # #Key: title Value: citation page url\n",
    "    cite = dict() #dict for storing the paper citatoin page (for citation)\n",
    "\n",
    "    heads = content.findAll('div', {\"class\": \"headline\"})\n",
    "    for head in heads:\n",
    "        # fetch the title in this paper\n",
    "        title = head.find('span', {\"class\": \"title\"}).getText()\n",
    "        print('processing paper: {}'.format(title))\n",
    "        # fetch the url for detail page & citation page\n",
    "        citation = head.find('div', {\"class\": \"headlineMenu\"})\n",
    "        menu_link = []\n",
    "        for i in citation.findAll('a', href=True):\n",
    "            menu_link.append(i['href'])\n",
    "\n",
    "        time.sleep(3)\n",
    "        #citation_page = 'https://mathscinet.ams.org/' + menu_link[-1] if (citation.getText().endswith(\"Citations\\n\") or citation.getText().endswith(\"Citation\\n\")) else None\n",
    "        if  citation.getText().endswith(\"Citation\\n\"):\n",
    "            citation_page = 'https://mathscinet.ams.org/' + menu_link[-1]\n",
    "            cite[title] = fetch_single_title(citation_page)\n",
    "        elif citation.getText().endswith(\"Citations\\n\"):\n",
    "            citation_page = 'https://mathscinet.ams.org/' + menu_link[-1]\n",
    "            cite[title] = fetch_title(citation_page)\n",
    "        else:\n",
    "            cite[title] = None\n",
    "    print(\"Check/Go next page\")\n",
    "    # continue for future work\n",
    "    next, next_url = findnext(url)\n",
    "    if next:\n",
    "        next_cite = fetch_citation(next_url)\n",
    "        total = {**cite, **next_cite}\n",
    "        return total\n",
    "    else:\n",
    "        return cite\n",
    "\n",
    "\n",
    "def fetch_title(url):\n",
    "    data = requests.get(url).content\n",
    "\n",
    "    content = BeautifulSoup(data, 'html.parser')\n",
    "    titles = []\n",
    "\n",
    "    heads = content.findAll('div', {\"class\": \"headline\"})\n",
    "    for head in heads:\n",
    "        # fetch the title in this paper\n",
    "        title = head.find('span', {\"class\": \"title\"}).getText()\n",
    "        titles.append(title)\n",
    "\n",
    "    # continue for future work\n",
    "    next, next_url = findnext(url)\n",
    "    if next:\n",
    "        next_titles = fetch_title(next_url)\n",
    "        titles.extend(next_titles)\n",
    "    return titles\n",
    "\n",
    "def fetch_single_title(url):\n",
    "    data = requests.get(url).content\n",
    "    content = BeautifulSoup(data, 'html.parser')\n",
    "    title = content.find('span', {\"class\": \"title\"}).getText()\n",
    "    return [title]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function fetches the citation for each authors in certain file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_citation():\n",
    "    with open('faculties.txt', 'r') as file:\n",
    "        data = file.read()\n",
    "        names = data.split('\\n')\n",
    "\n",
    "    result = dict()\n",
    "    idx = 1\n",
    "    for i in names:\n",
    "        print(\"{}/{}Checking:{}\\n\".format(idx, len(names), i))\n",
    "        time.sleep(2)\n",
    "        url = search(i)\n",
    "        citation = fetch_citation(url)\n",
    "        result[i] = citation\n",
    "        idx += 1\n",
    "\n",
    "    with open('data/citations_source.json', 'w') as file:\n",
    "        ujson.dump(result, file)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function outputs the joint citation matrix between any pair of authors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def citation_joint():\n",
    "    with open('data/citations_source.json', 'r') as file:\n",
    "        data = ujson.load(file)\n",
    "\n",
    "    total_citation = dict()\n",
    "    for i in data:\n",
    "        tmp = data[i]\n",
    "        total_citation[i] = set()\n",
    "        for k in tmp:\n",
    "            if tmp[k]:\n",
    "                for j in tmp[k]:\n",
    "                    total_citation[i].add(j)\n",
    "\n",
    "    pairs = combinations(total_citation, 2)\n",
    "    joint = dict()\n",
    "    for i in pairs:\n",
    "        one, two = i\n",
    "        joint[i] = len(total_citation[one] & total_citation[two])\n",
    "\n",
    "\n",
    "    with open('data/citation_joint.json', 'w') as file:\n",
    "        ujson.dump(joint, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functino is a variation of citation_joint. For any pair of authors, instead of the pure number of joint citation, this function outputs the paper's title of the joint citation publication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def citation_joint_name():\n",
    "    with open('data/citations_source.json', 'r') as file:\n",
    "        data = ujson.load(file)\n",
    "\n",
    "    total_citation = dict()\n",
    "    for i in data:\n",
    "        tmp = data[i]\n",
    "        total_citation[i] = set()\n",
    "        for k in tmp:\n",
    "            if tmp[k]:\n",
    "                for j in tmp[k]:\n",
    "                    total_citation[i].add(j)\n",
    "\n",
    "    pairs = combinations(total_citation, 2)\n",
    "    joint = dict()\n",
    "    for i in pairs:\n",
    "        one, two = i\n",
    "        joint[i] = list(total_citation[one] & total_citation[two])\n",
    "\n",
    "\n",
    "    with open('data/citation_joint_title', 'w') as file:\n",
    "        ujson.dump(joint, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function outpus the symmetrical citation matrix between any pair of authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def citation_directed():\n",
    "    with open('data/citations_source.json', 'r') as file:\n",
    "        data = ujson.load(file)\n",
    "\n",
    "    total_citation = dict()\n",
    "    for i in data:\n",
    "        tmp = data[i]\n",
    "        total_citation[i] = set()\n",
    "        for k in tmp:\n",
    "            if tmp[k]:\n",
    "                for j in tmp[k]:\n",
    "                    total_citation[i].add(j)\n",
    "    pairs = permutations(total_citation, 2) # for (one, two). How many time one takes reference of two's paper\n",
    "    directed = dict()\n",
    "    for i in pairs:\n",
    "        one, two = i\n",
    "        directed[i] = len(set(data[one]) & total_citation[two])\n",
    "\n",
    "    with open('data/citation_directed.json', 'w') as file:\n",
    "        ujson.dump(directed, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those following functions make citation/reference matrix for the total collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_citation_pool():\n",
    "    with open('data/citations_source.json', 'r') as file:\n",
    "        data = ujson.load(file)\n",
    "\n",
    "    citePool = set()\n",
    "    citeAuthor = defaultdict(list)\n",
    "    result = defaultdict(int)\n",
    "    for author in data:\n",
    "        for citation in data[author]:\n",
    "            if citation:\n",
    "                citeAuthor[author].append(citation)\n",
    "                citePool.add(citation)\n",
    "\n",
    "    for author in data:\n",
    "        for cite in citePool:\n",
    "            times = citeAuthor[author].count(cite)\n",
    "            result[(author, cite)] += times\n",
    "\n",
    "    with open('data/cite_pool.json', 'w') as file:\n",
    "        ujson.dump(result, file)\n",
    "\n",
    "def make_ref_pool():\n",
    "    ref_dic = dict()\n",
    "    ref_pool = set()\n",
    "    result = defaultdict(int)\n",
    "    with open('data/references_data.csv') as file:\n",
    "        data = csv.reader(file)\n",
    "        for row in data:\n",
    "            ids = row[2].replace(\"'\", '')[1:-1].split(', ')\n",
    "            ref_dic[row[1]] = ids\n",
    "            for id in ids:\n",
    "                ref_pool.add(id)\n",
    "    for author in ref_dic:\n",
    "        for ref in ref_pool:\n",
    "            times = ref_dic[author].count(ref)\n",
    "            result[(author, ref)] += times\n",
    "\n",
    "    with open('data/ref_pool.json', 'w') as file:\n",
    "        ujson.dump(result, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
